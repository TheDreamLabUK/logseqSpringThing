public:: true

- Natural Language Embedded Programs ([NLEP](https://news.mit.edu/2024/technique-improves-reasoning-capabilities-large-language-models-0614).) is a technique developed by researchers at MIT that enables large language models (LLMs) like GPT-4 to perform hybrid language-symbolic reasoning, combining natural language understanding with math, symbolic reasoning, and API calling capabilities[](https://arxiv.org/html/2309.10814v2)[](https://news.mit.edu/2024/technique-improves-reasoning-capabilities-large-language-models-0614).
	- NLEPs are programs containing both programming code (e.g., Python) and natural language comments/representations[](https://arxiv.org/html/2309.10814v2).
	- The LLM generates step-by-step programs with natural language comments guiding the program generation, structured knowledge represented in data structures, and natural language responses constructed from program variables[](https://arxiv.org/html/2309.10814v2).
	- This hybrid approach combines the benefits of language-based reasoning with program synthesis, enabling accurate computations and generalized problem-solving across various tasks[](https://arxiv.org/html/2309.10814v2)[](https://news.mit.edu/2024/technique-improves-reasoning-capabilities-large-language-models-0614).
	- NLEPs achieved over 90% accuracy on symbolic reasoning, question answering, instruction following, and text classification tasks, outperforming task-specific prompting methods and exhibiting better generalization[](https://arxiv.org/html/2309.10814v2)[](https://news.mit.edu/2024/technique-improves-reasoning-capabilities-large-language-models-0614).
	- NLEPs can improve data privacy by running programs locally without sending sensitive data to external models[](https://news.mit.edu/2024/technique-improves-reasoning-capabilities-large-language-models-0614).
	- The technique relies on the LLM's program generation capability, so it works better with larger models trained on extensive datasets
	- The NLEP research was conducted by Hongyin Luo, Tianhua Zhang, Jiaxin Ge, Yoon Kim, James Glass, and others at MIT[](https://arxiv.org/html/2309.10814v2)[](https://news.mit.edu/2024/technique-improves-reasoning-capabilities-large-language-models-0614).¬†An open-source implementation called LangCode is available on [GitHub](https://github.com/luohongyin/LangCode), enabling interactive NLEP generation on platforms like Colab and Jupyter notebooks.
- ## Deepseek R1
	- [(7) DeepSeek on X: "üöÄ DeepSeek-R1-Lite-Preview is now live: unleashing supercharged reasoning power! üîç o1-preview-level performance on AIME & MATH benchmarks. üí° Transparent thought process in real-time. üõ†Ô∏è Open-source models & API coming soon! üåê Try it now at https://t.co/v1TFy7LHNy #DeepSeek https://t.co/saslkq4a1s" / X](https://x.com/deepseek_ai/status/1859200145037869485/photo/1)
	- ![Gc0zl7WboAAnCTS.jpeg](../assets/Gc0zl7WboAAnCTS_1732126303552_0.jpeg)